{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime classification in San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= pd.read_csv('data/pre_processing_train_data.csv')\n",
    "train_data=train_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "37\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 X          Y      Year  X_Bar_District  Y_Bar_District  \\\n",
       "421375 -122.420926  37.762182  0.000000     -122.419409       37.759961   \n",
       "280407 -122.410769  37.783215  0.333333     -122.412503       37.783802   \n",
       "830654 -122.416829  37.788179 -1.000000     -122.409619       37.795685   \n",
       "87145  -122.412931  37.783834  0.833333     -122.412503       37.783802   \n",
       "404783 -122.412597  37.783932  0.000000     -122.412503       37.783802   \n",
       "\n",
       "        Sin_Year  Cos_Year  Sin_Hour  Cos_Hour  Sin_Day_m  Cos_Day_m  \\\n",
       "421375 -0.500000 -0.866025 -0.500000 -0.866025   0.968077  -0.250653   \n",
       "280407  0.725374 -0.688355  0.866025 -0.500000  -0.101168  -0.994869   \n",
       "830654  0.358368  0.933580  0.258819  0.965926  -0.897805  -0.440394   \n",
       "87145   0.548293  0.836286  0.500000  0.866025  -0.651372  -0.758758   \n",
       "404783 -0.426569 -0.904455 -0.258819 -0.965926   0.724793   0.688967   \n",
       "\n",
       "           Sin_Month     Cos_Month  Sin_Day_w  Cos_Day_w  \n",
       "421375  1.224647e-16 -1.000000e+00   0.781831   0.623490  \n",
       "280407 -5.000000e-01 -8.660254e-01  -0.974928  -0.222521  \n",
       "830654 -8.660254e-01 -5.000000e-01   0.433884  -0.900969  \n",
       "87145   1.000000e+00  6.123234e-17   0.974928  -0.222521  \n",
       "404783 -1.000000e+00 -1.836970e-16  -0.433884  -0.900969  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X</th>\n      <th>Y</th>\n      <th>Year</th>\n      <th>X_Bar_District</th>\n      <th>Y_Bar_District</th>\n      <th>Sin_Year</th>\n      <th>Cos_Year</th>\n      <th>Sin_Hour</th>\n      <th>Cos_Hour</th>\n      <th>Sin_Day_m</th>\n      <th>Cos_Day_m</th>\n      <th>Sin_Month</th>\n      <th>Cos_Month</th>\n      <th>Sin_Day_w</th>\n      <th>Cos_Day_w</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>421375</th>\n      <td>-122.420926</td>\n      <td>37.762182</td>\n      <td>0.000000</td>\n      <td>-122.419409</td>\n      <td>37.759961</td>\n      <td>-0.500000</td>\n      <td>-0.866025</td>\n      <td>-0.500000</td>\n      <td>-0.866025</td>\n      <td>0.968077</td>\n      <td>-0.250653</td>\n      <td>1.224647e-16</td>\n      <td>-1.000000e+00</td>\n      <td>0.781831</td>\n      <td>0.623490</td>\n    </tr>\n    <tr>\n      <th>280407</th>\n      <td>-122.410769</td>\n      <td>37.783215</td>\n      <td>0.333333</td>\n      <td>-122.412503</td>\n      <td>37.783802</td>\n      <td>0.725374</td>\n      <td>-0.688355</td>\n      <td>0.866025</td>\n      <td>-0.500000</td>\n      <td>-0.101168</td>\n      <td>-0.994869</td>\n      <td>-5.000000e-01</td>\n      <td>-8.660254e-01</td>\n      <td>-0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>830654</th>\n      <td>-122.416829</td>\n      <td>37.788179</td>\n      <td>-1.000000</td>\n      <td>-122.409619</td>\n      <td>37.795685</td>\n      <td>0.358368</td>\n      <td>0.933580</td>\n      <td>0.258819</td>\n      <td>0.965926</td>\n      <td>-0.897805</td>\n      <td>-0.440394</td>\n      <td>-8.660254e-01</td>\n      <td>-5.000000e-01</td>\n      <td>0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n    <tr>\n      <th>87145</th>\n      <td>-122.412931</td>\n      <td>37.783834</td>\n      <td>0.833333</td>\n      <td>-122.412503</td>\n      <td>37.783802</td>\n      <td>0.548293</td>\n      <td>0.836286</td>\n      <td>0.500000</td>\n      <td>0.866025</td>\n      <td>-0.651372</td>\n      <td>-0.758758</td>\n      <td>1.000000e+00</td>\n      <td>6.123234e-17</td>\n      <td>0.974928</td>\n      <td>-0.222521</td>\n    </tr>\n    <tr>\n      <th>404783</th>\n      <td>-122.412597</td>\n      <td>37.783932</td>\n      <td>0.000000</td>\n      <td>-122.412503</td>\n      <td>37.783802</td>\n      <td>-0.426569</td>\n      <td>-0.904455</td>\n      <td>-0.258819</td>\n      <td>-0.965926</td>\n      <td>0.724793</td>\n      <td>0.688967</td>\n      <td>-1.000000e+00</td>\n      <td>-1.836970e-16</td>\n      <td>-0.433884</td>\n      <td>-0.900969</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "train_sample = train_data.sample(n=10000)\n",
    "#dfsample = rebuild_data(df,dfsample) # new line added in order to imporve the sample\n",
    "train_labels=train_sample['Category']\n",
    "print(len(train_labels.unique()))\n",
    "train_labels.head()\n",
    "train_sample.drop('Category',inplace =True, axis=1)\n",
    "train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2000, 37)\nRandomForestClassifier(bootstrap=False, max_features='sqrt',\n                       min_samples_leaf=20, min_samples_split=40,\n                       n_estimators=150, random_state=42)\n[0.14678676 0.17622443 0.07556345 0.05266752 0.06841475 0.08413312\n 0.08353401 0.03550483 0.03868703 0.05756865 0.05002278 0.03649427\n 0.03242309 0.03722593 0.02474938]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 33, 37. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 29 30 31 35 37]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f2af42279410>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[0;32m   2263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2265\u001b[1;33m             raise ValueError(\"y_true and y_pred contain different number of \"\n\u001b[0m\u001b[0;32m   2266\u001b[0m                              \u001b[1;34m\"classes {0}, {1}. Please provide the true \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2267\u001b[0m                              \u001b[1;34m\"labels explicitly through the labels argument. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 33, 37. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 29 30 31 35 37]"
     ]
    }
   ],
   "source": [
    "# Load Library\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#X=(dfsample-dfsample.mean())/dfsample.std()\n",
    "X=train_sample\n",
    "y=train_labels\n",
    "\n",
    "# Split the training test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#  Fit a Random Forest model\n",
    "clf = RandomForestClassifier(n_estimators=150,max_depth=None,min_samples_leaf=20,min_samples_split=40,max_features='sqrt',bootstrap=False,random_state=42)\n",
    "#clf = MLPClassifier(hidden_layer_sizes=(100),solver='sgd',learning_rate='invscaling',random_state=1)\n",
    "#clf=KNeighborsClassifier(n_neighbors=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "p_pred = clf.predict_proba(X_test)\n",
    "print(p_pred.shape)\n",
    "print(clf)\n",
    "print(clf.feature_importances_)\n",
    "print(log_loss(y_test,p_pred))\n",
    "print(accuracy_score(y_test, np.argmax(p_pred,axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=150,max_depth=None,min_samples_leaf=20,min_samples_split=40,max_features='sqrt',bootstrap=False,random_state=42)\n",
    "\n",
    "clf.fit(train_sample, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'rdf_clf.joblib.pkl'\n",
    "_=joblib.dump(clf, filename, compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "# Number of trees in random forest\n",
    "n_estimators =[50,100,150]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [None,5,10,15]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [20,50,100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [10,20,50]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 50, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_random.best_params_)\n",
    "p_pred = rf_random.predict_proba(X_test)\n",
    "print(p_pred.shape)\n",
    "\n",
    "print(log_loss(p_pred,y_test))\n",
    "print(accuracy_score(y_test, np.argmax(p_pred,axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_rdf(X,y,nb_range=[100],mss_range=[10]):\n",
    "    n=len(nb_range)\n",
    "    m=len(mss_range)\n",
    "    res=np.zeros((n,m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            print((nb_range[i],mss_range[j]))\n",
    "            clf=RandomForestClassifier(n_estimators=nb_range[i],min_samples_split=mss_range[j],min_samples_leaf=mss_range[j]//2,)random_state=42)\n",
    "            scores=cross_val_score(clf,X,y)\n",
    "            score=np.mean(scores)\n",
    "            print(score)\n",
    "            res[i,j]=score\n",
    "    (imax,jmax)=np.unravel_index(res.argmax(), res.shape)\n",
    "    return (nb_range[imax],mss_range[jmax])\n",
    "\n",
    "cross_val_rdf(X,y,nb_range=[100,150,200],mss_range=[40,50,60])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python382jvsc74a57bd0abbcb8d9f889b21e7a35a6fd68ea23faf5197f2c8b5b2ec68133d2c93754c3b5",
   "display_name": "Python 3.8.2 32-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "48835d67319c7fa79cfd146833b8f8715a1d2e4cc5b6d93ebe0e6a7d47e9049f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}